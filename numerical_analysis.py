# -*- coding: utf-8 -*-
"""Numerical Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PC2lRva3l21OGY35eyU9OXvn_Xr6rQxJ

This notebook contains visualization for bias detection in peer reviewing by comparing SB and DB years. Precisely, it contains visualizations for experiment 1 and 2. Also statistical tests for exp-5.
"""

import pandas as pd
import pickle
import ast
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

# path where the pickle files with all the data is stored

data_path = '/content/drive/MyDrive/thesis-repository/data_17_19/numerical data/'

# make author names in a list

def format_auth_list(auth_names):
    new_list = auth_names.split(',')
    new_list = [i.strip() for i in new_list]
    return new_list

"""**Decision statistics of single author and multiple author**"""

# Data filter for papers written by a single author

# SB

df_2017 = pd.read_csv(open(f'{data_path}2017_decision.csv'))
df_2017 = df_2017[['title','decision','authors']]
df_2017.authors = df_2017.authors.apply(lambda x: format_auth_list(x))
df_2017 = df_2017[df_2017.decision != 'Invite to Workshop Track'].reset_index(drop=True)
df_2017['decision'] = df_2017['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_2017['auth_len'] = df_2017['authors'].apply(lambda x:len(x))
df_2017_one = df_2017[df_2017['auth_len'] == 1]


# DB
# 2018

df_dec_18 = pickle.load(open(f'{data_path}decision_18', 'rb'))
df_2018 = df_dec_18[df_dec_18.year == 2018]
df_2018 = df_2018[df_2018.decision != 'Invite to Workshop Track'].reset_index(drop=True)
df_2018['decision'] = df_2018['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_2018['auth_len'] = df_2018['Authors'].apply(lambda x:len(x))
df_2018_one = df_2018[df_2018['auth_len'] == 1]

# 2019

df_dec_19 = pickle.load(open(f'{data_path}all_decision_19.pkl', 'rb'))
df_dec_19 = df_dec_19.rename(columns={'recommendation':'decision'})
df_2019 = df_dec_19[df_dec_19.decision != 'Invite to Workshop Track'].reset_index(drop=True)
df_2019['decision'] = df_2019['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_2019['auth_len'] = df_2019['Authors'].apply(lambda x:len(x))
df_2019_one = df_2019[df_2019['auth_len'] == 1].reset_index(drop=True)

# calculating percentage of accept and rejected papers for one author papers

dec_17 = (df_2017_one.groupby(['decision']).size()/ len(df_2017_one)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
dec_18 = (df_2018_one.groupby(['decision']).size()/ len(df_2018_one)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
dec_19 = (df_2019_one.groupby(['decision']).size()/ len(df_2019_one)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
dec_17,dec_18,dec_19

# multiple authors paper for decision percentage

# SB

df_2017_m = pd.read_csv(open(f'{data_path}2017_decision.csv'))
df_2017_m = df_2017_m[['title','decision','authors']]
df_2017_m.authors = df_2017_m.authors.apply(lambda x: format_auth_list(x))
df_2017_m = df_2017_m[df_2017_m.decision != 'Invite to Workshop Track'].reset_index(drop=True)
df_2017_m['decision'] = df_2017_m['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_2017_m['auth_len'] = df_2017_m['authors'].apply(lambda x:len(x))
df_2017_m = df_2017_m[df_2017_m['auth_len'] != 1]
print(df_2017_m.decision.value_counts())

# DB
# 2018

df_dec_18_m = pickle.load(open(f'{data_path}decision_18', 'rb'))
df_2018_m = df_dec_18_m[df_dec_18_m.year == 2018]
df_2018_m = df_2018_m[df_2018_m.decision != 'Invite to Workshop Track'].reset_index(drop=True)
df_2018_m['decision'] = df_2018_m['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_2018_m['auth_len'] = df_2018_m['Authors'].apply(lambda x:len(x))
df_2018_m = df_2018_m[df_2018_m['auth_len'] != 1]
print(df_2018_m.decision.value_counts())


# 2019

df_dec_19_m = pickle.load(open(f'{data_path}all_decision_19.pkl', 'rb'))
df_dec_19_m = df_dec_19_m.rename(columns={'recommendation':'decision'})
df_2019_m = df_dec_19_m[df_dec_19_m.decision != 'Invite to Workshop Track'].reset_index(drop=True)
df_2019_m['decision'] = df_2019_m['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_2019_m['auth_len'] = df_2019_m['Authors'].apply(lambda x:len(x))
df_2019_m = df_2019_m[df_2019_m['auth_len'] != 1]
print(df_2019_m.decision.value_counts())

# calculate decision percentage for multiple authors

dec_17_m = (df_2017_m.groupby(['decision']).size()/ len(df_2017_m)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
dec_18_m = (df_2018_m.groupby(['decision']).size()/ len(df_2018_m)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
dec_19_m = (df_2019_m.groupby(['decision']).size()/ len(df_2019_m)*100).reset_index().rename({0:'percentage_count'}, axis=1 )

# plot papers decision ratio
palette = [ "#ffcc00","#993300",]
fig, ax = plt.subplots(2, 3, figsize=(11,6),sharex=True,sharey=True)
sns.barplot(x = 'decision',data = dec_17_m,y='percentage_count',ax=ax[0,0],palette=palette)
sns.barplot(x = 'decision',data = dec_18_m,y='percentage_count',ax=ax[0,1],palette=palette)
sns.barplot(x = 'decision',data = dec_19_m,y='percentage_count',ax=ax[0,2],palette=palette)
sns.barplot(x = 'decision',data = dec_17,y='percentage_count',ax=ax[1,0],palette=palette)
sns.barplot(x = 'decision',data = dec_18,y='percentage_count',ax=ax[1,1],palette=palette)
sns.barplot(x = 'decision',data = dec_19,y='percentage_count',ax=ax[1,2],palette=palette)
fig.tight_layout()
ax[0,1].set_ylabel('')
ax[0,2].set_ylabel('')
ax[0,0].set_xlabel('')
ax[0,1].set_xlabel( 'Multiple Author')
ax[0,2].set_xlabel('')
ax[1,0].set_xlabel('')
ax[1,2].set_xlabel('')
ax[1,1].set_ylabel('')
ax[1,2].set_ylabel('')
ax[1,1].set_xlabel('Single Author')
ax[0,0].bar_label(ax[0,0].containers[0], fmt='%.2f',weight='bold')
ax[0,1].bar_label(ax[0,1].containers[0], fmt='%.2f',weight='bold')
ax[0,2].bar_label(ax[0,2].containers[0], fmt='%.2f',weight='bold')
ax[1,0].bar_label(ax[1,0].containers[0], fmt='%.2f',weight='bold')
ax[1,1].bar_label(ax[1,1].containers[0], fmt='%.2f',weight='bold')
ax[1,2].bar_label(ax[1,2].containers[0], fmt='%.2f',weight='bold')
fig.suptitle('Decision Percentage',y=1.1)
ax[0,0].set_title('SB-2017')
ax[0,1].set_title('DB-2018')
ax[0,2].set_title('DB-2019')
plt.savefig('decision.pdf', bbox_inches="tight")
fig.show()

def get_rev_len(text):
  len_list = [len(i) for i in text]
  return len_list

"""**Data preperation for multiple authors**"""

# Seggregation of review and author data for analysis - multiple author

rev_col = ['title','decision','rating_score', 'rating_text', 'confidence_score', 'confidence_text','review']
auth_col = ['title', 'decision','Authors', 'academic_age','current_age', 'total_num_pub',]
col = ['title', 'decision', 'year', 'Authors', 'rating_score', 'rating_text', 'review', 'confidence_score', 'confidence_text',
       'academic_age','current_age', 'total_num_pub', ]
# oral_all = pickle.load(open(f'{data_path}all_oral.pkl', 'rb'))
# oral_all = oral_all[col]

# SB

df_17_all_m = pickle.load(open(f'{data_path}all_data_17.pkl', 'rb'))
# oral_17 = oral_all[oral_all.year == 2017].reset_index(drop=True)
# df_17_all = pd.concat([df_17_all,oral_17]).reset_index(drop=True)
# df_17_all['decision'] = df_17_all['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_17_rev_m = df_17_all_m[rev_col]
df_17_rev_m['review_len'] = df_17_rev_m.apply(lambda x: get_rev_len(x['review']),axis=1)
df_17_rev_m['avg_rev_len'] = df_17_rev_m['review_len'].apply(lambda x: np.average(x, weights=x))
df_17_rev_m['confidence_score'] = df_17_rev_m['confidence_score'].apply(lambda x: [int(i) for i in x])
df_17_rev_m['avg_cs'] = df_17_rev_m['confidence_score'].apply(lambda x: np.average(x, weights=x))
df_17_rev_m['avg_rating'] = df_17_rev_m['rating_score'].apply(lambda x: np.average(x, weights=x))
df_17_auth_m = df_17_all_m[auth_col]

# 2018

df_18_all_m = pickle.load(open(f'{data_path}all_data_18.pkl', 'rb'))
df_18_all_m = df_18_all_m.rename(columns = {'Title':'title'})
# oral_18 = oral_all[oral_all.year == 2018].reset_index(drop=True)
# df_18_all = pd.concat([df_18_all,oral_18]).reset_index(drop=True)
# df_18_all['decision'] = df_18_all['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_18_rev_m = df_18_all_m[rev_col]
df_18_rev_m['review_len'] = df_18_rev_m.apply(lambda x: get_rev_len(x['review']),axis=1)
df_18_rev_m['avg_rev_len'] = df_18_rev_m['review_len'].apply(lambda x: np.average(x, weights=x))
df_18_rev_m['avg_cs'] = df_18_rev_m['confidence_score'].apply(lambda x: np.average(x, weights=x))
df_18_rev_m['avg_rating'] = df_18_rev_m['rating_score'].apply(lambda x: np.average(x, weights=x))
df_18_auth_m = df_18_all_m[auth_col]

# 2019

df_19_all_m = pickle.load(open(f'{data_path}all_data_19.pkl', 'rb'))
# df_19_all = df_19_all.rename(columns={'recommendation':'decision'})
# oral_19 = oral_all[oral_all.year == 2019].reset_index(drop=True)
# df_19_all = pd.concat([df_19_all,oral_19]).reset_index(drop=True)
# df_19_all['decision'] = df_19_all['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
# df_19_all = df_19_all.rename(columns = {'Title':'title'})
df_19_rev_m = df_19_all_m[rev_col]
df_19_rev_m['review_len'] = df_19_rev_m.apply(lambda x: get_rev_len(x['review']),axis=1)
df_19_rev_m['avg_rev_len'] = df_19_rev_m['review_len'].apply(lambda x: np.average(x, weights=x))
df_19_rev_m['avg_cs'] = df_19_rev_m['confidence_score'].apply(lambda x: np.average(x, weights=x))
df_19_rev_m['avg_rating'] = df_19_rev_m['rating_score'].apply(lambda x: np.average(x, weights=x))
df_19_auth_m = df_19_all_m[auth_col]
df_19_auth_m = df_19_auth_m.loc[:,~df_19_auth_m.columns.duplicated()].copy()
df_19_rev_m = df_19_rev_m.loc[:,~df_19_rev_m.columns.duplicated()].copy()

# Prepare data for next review related analysis - multiple author

# SB

df_17_rev_a_m = df_17_rev_m[['title','decision', 'rating_score', 'confidence_score','confidence_text','review_len','rating_text']]
df_rev_17_e_m = df_17_rev_a_m.explode(df_17_rev_a_m.columns.tolist()[2:]).reset_index(drop=True)
df_rev_17_e_m['rating_score'] = df_rev_17_e_m['rating_score'].astype(int)
df_rev_17_e_m['confidence_score'] = df_rev_17_e_m['confidence_score'].astype(int)

# 2018

df_18_rev_a_m = df_18_rev_m[['title','decision', 'rating_score', 'confidence_score','confidence_text','review_len','rating_text']]
df_rev_18_e_m = df_18_rev_a_m.explode(df_18_rev_a_m.columns.tolist()[2:]).reset_index(drop=True)
df_rev_18_e_m['rating_score'] = df_rev_18_e_m['rating_score'].astype(int)
df_rev_18_e_m['confidence_score'] = df_rev_18_e_m['confidence_score'].astype(int)

# 2019

df_19_rev_a_m = df_19_rev_m[['title','decision', 'rating_score', 'confidence_score','confidence_text','review_len','rating_text']]
df_rev_19_e_m = df_19_rev_a_m.explode(df_19_rev_a_m.columns.tolist()[2:]).reset_index(drop=True)
df_rev_19_e_m['rating_score'] = df_rev_19_e_m['rating_score'].astype(int)
df_rev_19_e_m['confidence_score'] = df_rev_19_e_m['confidence_score'].astype(int)

"""**Confidence Score Statistics**"""

# multiple authors

cs_18 = (df_rev_18_e_m.groupby(['confidence_score']).size() / len(df_rev_18_e_m)*100).reset_index().rename({0:'percentage_count'}, axis=1)
cs_19 = (df_rev_19_e_m.groupby(['confidence_score']).size() / len(df_rev_19_e_m)*100).reset_index().rename({0:'percentage_count'}, axis=1)
cs_17 = (df_rev_17_e_m.groupby(['confidence_score']).size() /len(df_rev_17_e_m)*100).reset_index().rename({0:'percentage_count'}, axis=1)

fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12,4))
sns.barplot(data=cs_17,x='confidence_score',y='percentage_count',ax=ax1,errorbar=None,color='#ff9999')
sns.barplot(data=cs_18,x='confidence_score',y='percentage_count', ax=ax2,errorbar=None,color='#ff9999')
sns.barplot(data=cs_19,x='confidence_score',y='percentage_count', ax=ax3,errorbar=None,color='#ff9999')
fig.suptitle('Confidence Score Stasistics',y=1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold')
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold')
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold')
ax2.set_ylabel('')
ax3.set_ylabel('')
ax1.set_xlabel('')
ax3.set_xlabel('')
ax1.set_ylim([0,60])
ax2.set_ylim([0,60])
ax3.set_ylim([0,60])
# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
fig.tight_layout()
plt.savefig("cs_statistics.png", bbox_inches="tight")
fig.show()

def get_conf_labels(conf):
  if conf<3:
    return 'Less confident'
  elif conf == 3:
    return 'Medium Confident'
  else:
    return 'Confident'

df_rev_17_e_m['rev_conf'] = df_rev_17_e_m.apply(lambda x: get_conf_labels(x['confidence_score']),axis=1)
df_rev_18_e_m['rev_conf'] = df_rev_18_e_m.apply(lambda x: get_conf_labels(x['confidence_score']),axis=1)
df_rev_19_e_m['rev_conf'] = df_rev_19_e_m.apply(lambda x: get_conf_labels(x['confidence_score']),axis=1)

conf_17 = (df_rev_17_e_m.groupby(['decision','rev_conf']).size() / df_rev_17_e_m.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

conf_18 = (df_rev_18_e_m.groupby(['decision','rev_conf']).size() / df_rev_18_e_m.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

conf_19 = (df_rev_19_e_m.groupby(['decision','rev_conf']).size() / df_rev_19_e_m.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

"""**Confidence of Reviewers vs Paper Decision**"""

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(17, 4.5))
palette = [ "#ffcc00","#993300",]
sns.barplot(hue ='decision', y ='percentage_count',x='rev_conf', data = conf_17,errorbar=('ci', 0),
            order=['Confident','Medium Confident','Less confident'],ax=ax1,palette=palette).legend_.remove()
sns.barplot(hue ='decision', y ='percentage_count',x='rev_conf', data = conf_18,
            errorbar=('ci', 0),ax=ax2,order=['Confident','Medium Confident','Less confident'],palette=palette)
sns.barplot(hue ='decision', y ='percentage_count',x='rev_conf', data = conf_19,
            errorbar=('ci', 0),ax=ax3,order=['Confident','Medium Confident','Less confident'],palette=palette).legend_.remove()
fig.suptitle('Confidence score with decision Stasistics',y=1)
ax1.set_ylabel("Percentage")
ax2.set_ylabel('')
ax3.set_ylabel('')

ax3.set_xlabel('')
ax1.set_xlabel('')
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
ax1.set_ylabel('Percentage_count',fontdict={ 'fontsize': 12})
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.1f',weight='bold',fontsize=12)
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.1f',weight='bold',fontsize=12)
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.1f',weight='bold',fontsize=12)
ax1.set_ylim([0,100])
ax2.set_ylim([0,100])
ax3.set_ylim([0,100])
# ax1.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
ax2.legend(loc="upper center", bbox_to_anchor=(0.5, -.08), ncol=2,fontsize=13)
ax2.set_xlabel('\n\n\nConfidence Category of Reviewer',fontdict={ 'fontsize': 12})
plt.savefig("cs_decision.png", bbox_inches="tight")
plt.show()

"""**Reviewers’ Confidence vs Ratings**"""

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(16, 4.5))
col_order=['Less confident','Medium Confident','Confident']
palette = ["#9999ff","#666699", "#000066",]
sns.barplot(data=df_rev_17_e_m,x='rev_conf',y='rating_score',ax=ax1,estimator=np.mean,errorbar=None
,order=col_order,palette=palette)
sns.barplot(data=df_rev_18_e_m,x='rev_conf',y='rating_score',ax=ax2,estimator=np.mean,errorbar=None
,order=col_order,palette=palette)
sns.barplot(data=df_rev_19_e_m,x='rev_conf',y='rating_score',ax=ax3,estimator=np.mean,errorbar=None
,order=col_order,palette=palette)
fig.suptitle('Rating Score vs Confidence score Stasistics',y=1.06)
ax1.set_ylabel("rating")
ax2.set_ylabel('')
ax3.set_ylabel('')
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
ax1.set_ylim([0,7.5])
ax2.set_ylim([0,7.5])
ax3.set_ylim([0,7.5])
ax1.set_xlabel('')
ax3.set_xlabel('')
ax2.set_xlabel('\n Confidence Level',fontdict={ 'fontsize': 12})
ax1.set_ylabel('Average rating',fontdict={ 'fontsize': 12})
plt.savefig("CS_Rating.png", bbox_inches="tight")
plt.show()

"""**Data preperation for single authors**"""

# prepare data for single author papers

# data preprocessing and manual search for any missed data

# 2017

df_17_all = pickle.load(open(f'{data_path}all_data_17.pkl', 'rb'))
df_17_all['auth_len'] = df_17_all['Authors'].apply(lambda x:len(x))
df_17_one = df_17_all[df_17_all['auth_len'] == 1].reset_index(drop=True)
df_17_one.loc[0,'academic_age'] = [5]
df_17_one.loc[0,'current_age'] = [7]
df_17_one.loc[0,'total_num_pub'] = [5]
df_17_one.loc[6,'academic_age'] = [38]
df_17_one.loc[6,'current_age'] = [40]
df_17_one.loc[6,'total_num_pub'] = [53]
df_17_one.loc[9,'academic_age'] = [20]
df_17_one.loc[9,'current_age'] = [22] # 15 no match
df_17_one.loc[9,'total_num_pub'] = [14]

# 2018

df_18_all = pickle.load(open(f'{data_path}all_data_18.pkl', 'rb'))
df_18_all['auth_len'] = df_18_all['Authors'].apply(lambda x:len(x))
df_18_one = df_18_all[df_18_all['auth_len'] == 1].reset_index(drop=True)
df_18_one.loc[3,'academic_age'] = [13] #1
df_18_one.loc[3,'current_age'] = [19]
df_18_one.loc[3,'total_num_pub'] = [92]
df_18_one.loc[4,'academic_age'] = [10]
df_18_one.loc[4,'current_age'] = [11]
df_18_one.loc[4,'total_num_pub'] = [9]
df_18_one.loc[5,'academic_age'] = [3]
df_18_one.loc[5,'current_age'] = [9]
df_18_one.loc[5,'total_num_pub'] = [33] # 6,25 no match
df_18_one.loc[21,'academic_age'] = [-3]
df_18_one.loc[21,'current_age'] = [4]
df_18_one.loc[21,'total_num_pub'] = [2]
df_18_one.loc[26,'academic_age'] = [27]
df_18_one.loc[26,'current_age'] = [33]
df_18_one.loc[26,'total_num_pub'] = [116]
df_18_one = df_18_one.rename(columns={'Title':'title'})
df_18_one = df_18_one.drop(index=1)

# 2019

df_19_all = pickle.load(open(f'{data_path}all_data_19.pkl', 'rb'))
df_19_all = df_19_all.rename(columns={'recommendation':'decision'})
df_19_all['auth_len'] = df_19_all['Authors'].apply(lambda x:len(x))
df_19_one = df_19_all[df_19_all['auth_len'] == 1].reset_index(drop=True)
df_19_one.loc[40,'academic_age'] = [20] #1
df_19_one.loc[40,'current_age'] = [24]
df_19_one.loc[40,'total_num_pub'] = [52]
df_19_one = df_19_one.drop(index=24)


df_17_one['review_len'] = df_17_one.apply(lambda x: get_rev_len(x['review']),axis=1)
df_17_one['decision'] = df_17_one['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_18_one['review_len'] = df_18_one.apply(lambda x: get_rev_len(x['review']),axis=1)
df_18_one['decision'] = df_18_one['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_19_one['review_len'] = df_19_one.apply(lambda x: get_rev_len(x['review']),axis=1)
df_19_one['decision'] = df_19_one['decision'] .apply(lambda x:'Accept' if x.startswith('Accept') else 'Reject')
df_19_one = df_19_one.rename(columns={'Title':'title'})

col = ['title', 'decision', 'year', 'Authors', 'rating_score', 'rating_text', 'review', 'confidence_score', 'confidence_text',
       'academic_age','current_age', 'total_num_pub', ]
rev_col = ['title','Authors','decision','rating_score', 'rating_text', 'confidence_score', 'confidence_text','review']
auth_col = ['title', 'decision','Authors', 'academic_age','current_age', 'total_num_pub',]



df_17_rev_one = df_17_one[rev_col]
df_17_auth_one = df_17_one[auth_col]
df_18_rev_one = df_18_one[rev_col]
df_18_auth_one = df_18_one[auth_col]
df_19_rev_one = df_19_one[rev_col]
df_19_auth_one = df_19_one[auth_col]

# 2017

df_17_rev_a = df_17_rev_one[['title','decision','Authors', 'rating_score', 'confidence_score','confidence_text','rating_text','review']]
df_rev_17_e = df_17_rev_a.explode(df_17_rev_a.columns.tolist()[3:]).reset_index(drop=True)
df_rev_17_e['rating_score'] = df_rev_17_e['rating_score'].astype(int)
df_rev_17_e['confidence_score'] = df_rev_17_e['confidence_score'].astype(int)

# 2018

df_18_rev_a = df_18_rev_one[['title','decision', 'Authors','rating_score', 'confidence_score','confidence_text','rating_text','review']]
df_rev_18_e = df_18_rev_a.explode(df_18_rev_a.columns.tolist()[3:]).reset_index(drop=True)
df_rev_18_e['rating_score'] = df_rev_18_e['rating_score'].astype(int)
df_rev_18_e['confidence_score'] = df_rev_18_e['confidence_score'].astype(int)

# 2019

df_19_rev_a = df_19_rev_one[['title','decision','Authors', 'rating_score', 'confidence_score','confidence_text','rating_text','review']]
df_rev_19_e = df_19_rev_a.explode(df_19_rev_a.columns.tolist()[3:]).reset_index(drop=True)
df_rev_19_e['rating_score'] = df_rev_19_e['rating_score'].astype(int)
df_rev_19_e['confidence_score'] = df_rev_19_e['confidence_score'].astype(int)

"""**Rating Score of Reviewers**"""

# single authors

rs_18 = (df_rev_18_e.groupby(['rating_score',]).size() / len(df_rev_18_e)).reset_index().rename({0:'percentage_count'}, axis=1)
rs_19 = (df_rev_19_e.groupby(['rating_score',]).size() / len(df_rev_19_e)).reset_index().rename({0:'percentage_count'}, axis=1)
sb_rs = (df_rev_17_e.groupby(['rating_score',]).size() / len(df_rev_17_e)).reset_index().rename({0:'percentage_count'}, axis=1)


fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(14, 4.5))
sns.barplot(data=sb_rs,x='rating_score',y='percentage_count', color='#999900',ax=ax1)
sns.barplot(data=rs_18,x='rating_score',y='percentage_count', color='#999900',ax=ax2)
sns.barplot(data=rs_19,x='rating_score',y='percentage_count', color='#999900',ax=ax3)
fig.suptitle('Rating Score Stasistics',y=1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold')
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold')
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold')
ax2.set_ylabel('')
ax3.set_ylabel('')
ax1.set_xlabel('')
ax3.set_xlabel('')
ax1.set_ylim([0,.3])
ax2.set_ylim([0,.3])
ax3.set_ylim([0,.3])
ax1.set_ylabel('Percentage_count',fontdict={ 'fontsize': 12})
ax2.set_xlabel('Ratings single author',fontdict={ 'fontsize': 12})
# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
fig.tight_layout()
plt.savefig("rating_one.png",  bbox_inches="tight")
fig.show()

# ratings multiple author

rs_18_m = (df_rev_18_e_m.groupby(['rating_score',]).size() / len(df_rev_18_e_m)).reset_index().rename({0:'percentage_count'}, axis=1)
rs_19_m = (df_rev_19_e_m.groupby(['rating_score',]).size() / len(df_rev_19_e_m)).reset_index().rename({0:'percentage_count'}, axis=1)
sb_rs_m = (df_rev_17_e_m.groupby(['rating_score',]).size() / len(df_rev_17_e_m)).reset_index().rename({0:'percentage_count'}, axis=1)


fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(13.5, 4.5))
sns.barplot(data=sb_rs_m,x='rating_score',y='percentage_count', color='#999900',ax=ax1)
sns.barplot(data=rs_18_m,x='rating_score',y='percentage_count', color='#999900',ax=ax2)
sns.barplot(data=rs_19_m,x='rating_score',y='percentage_count', color='#999900',ax=ax3)
fig.suptitle('Rating Score Stasistics',y=1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold')
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold')
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold')
ax2.set_ylabel('')
ax3.set_ylabel('')
ax1.set_xlabel('')
ax3.set_xlabel('')
ax1.set_ylabel('Percentage_count',fontdict={ 'fontsize': 12})
ax2.set_xlabel('Ratings multiple authors',fontdict={ 'fontsize': 12})
ax1.set_ylim([0,.3])
ax2.set_ylim([0,.3])
ax3.set_ylim([0,.3])
# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
fig.tight_layout()
plt.savefig("rating_multi.png",  bbox_inches="tight")
fig.show()

"""**Review Length**"""

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(13, 4))
sns.boxplot(data=df_rev_17_e_m,x='review_len',ax=ax1,showfliers=False,color='#669999')
sns.boxplot(data=df_rev_18_e_m,x='review_len',ax=ax2,showfliers=False,color='#669999')
sns.boxplot(data=df_rev_19_e_m,x='review_len',ax=ax3,showfliers=False,color='#669999')
# ax1.set_ylabel('Count')
ax2.set_ylabel('')
ax3.set_ylabel('')
fig.suptitle('Statistics of Review Length',y=1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
# ax1.set_ylim([0,120])
ax1.set_xlim([0,6000])
ax2.set_xlim([0,6000])
ax3.set_xlim([0,6000])
ax3.set_xlabel('')
ax1.set_xlabel('')
ax2.set_xlabel('Review_length',fontdict={ 'fontsize': 12})

fig.tight_layout()
plt.savefig("review_length.png", bbox_inches="tight")
fig.show()

# statistical validity testing

from scipy.stats import mannwhitneyu

rev_len_17 = df_rev_17_e_m['review_len'].tolist()
rev_len_18 = df_rev_18_e_m['review_len'].tolist()
rev_len_19 = df_rev_19_e_m['review_len'].tolist()

rev_len_17  = np.array(rev_len_17)
rev_len_18  = np.array(rev_len_18)
rev_len_19  = np.array(rev_len_19)

statistic, p_value = mannwhitneyu(rev_len_17, rev_len_18)
print(f"U Statistic: {statistic}")
print(f"P-Value: {p_value}")

statistic, p_value = mannwhitneyu(rev_len_17, rev_len_19)
print(f"U Statistic: {statistic}")
print(f"P-Value: {p_value}")

"""# **Author centric Analysis**

**Data preperation**
"""

def get_age_labels(age):
  if age<=3:
    return 'Junior'
  elif age>3 and age<=10: # keep
    return 'Intermediate'
  elif age>10:
    return 'Senior'

# Format and preprocess author data for analysis for multiple author

# SB

df_17_auth_m['auth_len'] =  df_17_auth_m['Authors'].apply(lambda x:len(x))
df_17_auth_m['age_len'] =  df_17_auth_m['academic_age'].apply(lambda x:len(x))
df_17_auth_m['nop_len'] =  df_17_auth_m['total_num_pub'].apply(lambda x:len(x))

df_17_auth_m['len_diff_age'] = df_17_auth_m['auth_len'] - df_17_auth_m['age_len']
df_17_auth_m['len_diff_nop'] = df_17_auth_m['auth_len'] - df_17_auth_m['nop_len']
df_17_auth_new_m = df_17_auth_m[df_17_auth_m.len_diff_age == 0]
df_17_auth_new_m = df_17_auth_new_m[df_17_auth_m.columns.tolist()[:6]].reset_index(drop=True)
df_17_auth_new_m = df_17_auth_new_m.drop(index=348)
df_17_auth_e_m = df_17_auth_new_m.explode(df_17_auth_new_m.columns.tolist()[2:])
new_17_auth_m = df_17_auth_e_m[~(df_17_auth_e_m['total_num_pub'].isin(['skipped','no_match','no match']))].reset_index(drop=True)

# 2018

df_18_auth_m['auth_len'] =  df_18_auth_m['Authors'].apply(lambda x:len(x))
df_18_auth_m['age_len'] =  df_18_auth_m['academic_age'].apply(lambda x:len(x))
df_18_auth_m['nop_len'] =  df_18_auth_m['total_num_pub'].apply(lambda x:len(x))

df_18_auth_m['len_diff_age'] = df_18_auth_m['auth_len'] - df_18_auth_m['age_len']
df_18_auth_m['len_diff_nop'] = df_18_auth_m['auth_len'] - df_18_auth_m['nop_len']
df_18_auth_new_m = df_18_auth_m[df_18_auth_m.len_diff_nop == 0]
df_18_auth_new_m = df_18_auth_new_m[df_18_auth_m.columns.tolist()[:6]].reset_index(drop=True)
df_18_auth_e_m = df_18_auth_new_m.explode(df_18_auth_new_m.columns.tolist()[2:])
new_18_auth_m = df_18_auth_e_m[~(df_18_auth_e_m['total_num_pub'].isin(['skipped','no_match','no match']))].reset_index(drop=True)

# 2019

df_19_auth_m['auth_len'] =  df_19_auth_m['Authors'].apply(lambda x:len(x))
df_19_auth_m['age_len'] =  df_19_auth_m['academic_age'].apply(lambda x:len(x))
df_19_auth_m['nop_len'] =  df_19_auth_m['total_num_pub'].apply(lambda x:len(x))

df_19_auth_m['len_diff_age'] = df_19_auth_m['auth_len'] - df_19_auth_m['age_len']
df_19_auth_m['len_diff_nop'] = df_19_auth_m['auth_len'] - df_19_auth_m['nop_len']
df_19_auth_new_m = df_19_auth_m[df_19_auth_m.len_diff_nop == 0]
df_19_auth_new_m = df_19_auth_new_m[df_19_auth_new_m.columns.tolist()[:6]].reset_index(drop=True)
df_19_auth_e_m = df_19_auth_new_m.explode(df_19_auth_new_m.columns.tolist()[2:])
new_19_auth_m = df_19_auth_e_m[~(df_19_auth_e_m['total_num_pub'].isin(['skipped','no_match','no match']))].reset_index(drop=True)

new_17_auth_m['author_category'] = new_17_auth_m.apply(lambda x: get_age_labels(x['academic_age']),axis=1)
new_18_auth_m['author_category'] = new_18_auth_m.apply(lambda x: get_age_labels(x['academic_age']),axis=1)
new_19_auth_m['author_category'] = new_19_auth_m.apply(lambda x: get_age_labels(x['academic_age']),axis=1)

df_17_m = (new_17_auth_m.groupby(['author_category']).size()/ len(new_17_auth_m)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
df_18_m = (new_18_auth_m.groupby(['author_category']).size()/ len(new_18_auth_m)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
df_19_m = (new_19_auth_m.groupby(['author_category']).size()/ len(new_19_auth_m)*100).reset_index().rename({0:'percentage_count'}, axis=1 )

cat_sb_m = (new_17_auth_m.groupby(['decision','author_category']).size() / new_17_auth_m.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

cat_18_m = (new_18_auth_m.groupby(['decision','author_category']).size() / new_18_auth_m.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

cat_19_m = (new_19_auth_m.groupby(['decision','author_category']).size() / new_19_auth_m.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

new_17_auth_m.head()

# Format and preprocess author data for analysis for single author

df_17_auth_e = df_17_auth_one.explode(df_17_auth_one.columns.tolist()[2:])
df_18_auth_e = df_18_auth_one.explode(df_18_auth_one.columns.tolist()[2:])
df_19_auth_e = df_19_auth_one.explode(df_18_auth_one.columns.tolist()[2:])
new_17_auth_s = df_17_auth_e[df_17_auth_e.academic_age!='skipped']
new_18_auth_s = df_18_auth_e[df_18_auth_e.academic_age!='no_match']
new_19_auth_s = df_19_auth_e[~(df_19_auth_e.academic_age.isin(['no_match','skipped','no match']))]

new_17_auth_s['author_category'] = new_17_auth_s.apply(lambda x: get_age_labels(x['academic_age']),axis=1)
new_18_auth_s['author_category'] = new_18_auth_s.apply(lambda x: get_age_labels(x['academic_age']),axis=1)
new_19_auth_s['author_category'] = new_19_auth_s.apply(lambda x: get_age_labels(x['academic_age']),axis=1)

df_17_s = (new_17_auth_s.groupby(['author_category']).size()/ len(new_17_auth_s)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
df_18_s = (new_18_auth_s.groupby(['author_category']).size()/ len(new_18_auth_s)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
df_19_s = (new_19_auth_s.groupby(['author_category']).size()/ len(new_19_auth_s)*100).reset_index().rename({0:'percentage_count'}, axis=1 )

cat_sb_s = (new_17_auth_s.groupby(['decision','author_category']).size() / new_17_auth_s.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

cat_18_s = (new_18_auth_s.groupby(['decision','author_category']).size() / new_18_auth_s.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

cat_19_s = (new_19_auth_s.groupby(['decision','author_category']).size() / new_19_auth_s.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

# Format and preprocess author data for analysis for first author

def get_first_auth_info(data_list):
  fa_info = [i for i in data_list][0]
  return fa_info

df_17_fa = df_17_auth_new_m.copy()
df_18_fa = df_18_auth_new_m.copy()
df_19_fa = df_19_auth_new_m.copy()

df_17_fa = df_17_auth_new_m.copy()
df_18_fa = df_18_auth_new_m.copy()
df_19_fa = df_19_auth_new_m.copy()

# get first author details

# 2017

df_17_fa['fa_name'] = df_17_fa['Authors'].apply(lambda x:get_first_auth_info(x))
df_17_fa['fa_aa'] = df_17_fa['academic_age'].apply(lambda x:get_first_auth_info(x))
df_17_fa['fa_ca'] = df_17_fa['current_age'].apply(lambda x:get_first_auth_info(x))
df_17_fa['fa_nop'] = df_17_fa['total_num_pub'].apply(lambda x:get_first_auth_info(x))
df_17_fa_new = df_17_fa[['title','decision','fa_name','fa_aa','fa_ca','fa_nop']]
df_17_fa_new = df_17_fa_new[~(df_17_fa_new['fa_nop'].isin(['skipped','no_match','no match']))].reset_index(drop=True) # filter the skipped authors

# 2018

df_18_fa['fa_name'] = df_18_fa['Authors'].apply(lambda x:get_first_auth_info(x))
df_18_fa['fa_aa'] = df_18_fa['academic_age'].apply(lambda x:get_first_auth_info(x))
df_18_fa['fa_ca'] = df_18_fa['current_age'].apply(lambda x:get_first_auth_info(x))
df_18_fa['fa_nop'] = df_18_fa['total_num_pub'].apply(lambda x:get_first_auth_info(x))
df_18_fa_new = df_18_fa[['title','decision','fa_name','fa_aa','fa_ca','fa_nop']]
df_18_fa_new = df_18_fa_new[~(df_18_fa_new['fa_nop'].isin(['skipped','no_match','no match']))].reset_index(drop=True) # filter the skipped authors

# 2019

df_19_fa['fa_name'] = df_19_fa['Authors'].apply(lambda x:get_first_auth_info(x))
df_19_fa['fa_aa'] = df_19_fa['academic_age'].apply(lambda x:get_first_auth_info(x))
df_19_fa['fa_ca'] = df_19_fa['current_age'].apply(lambda x:get_first_auth_info(x))
df_19_fa['fa_nop'] = df_19_fa['total_num_pub'].apply(lambda x:get_first_auth_info(x))
df_19_fa_new = df_19_fa[['title','decision','fa_name','fa_aa','fa_ca','fa_nop']]
df_19_fa_new = df_19_fa_new[~(df_19_fa_new['fa_nop'].isin(['skipped','no_match','no match']))].reset_index(drop=True) # filter the skipped authors

df_17_fa_new['author_category'] = df_17_fa_new.apply(lambda x: get_age_labels(x['fa_aa']),axis=1)
df_18_fa_new['author_category'] = df_18_fa_new.apply(lambda x: get_age_labels(x['fa_aa']),axis=1)
df_19_fa_new['author_category'] = df_19_fa_new.apply(lambda x: get_age_labels(x['fa_aa']),axis=1)


df_17_fa = (df_17_fa_new.groupby(['author_category']).size()/ len(df_17_fa_new)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
df_18_fa = (df_18_fa_new.groupby(['author_category']).size()/ len(df_18_fa_new)*100).reset_index().rename({0:'percentage_count'}, axis=1 )
df_19_fa = (df_19_fa_new.groupby(['author_category']).size()/ len(df_19_fa_new)*100).reset_index().rename({0:'percentage_count'}, axis=1 )

cat_sb_fa = (df_17_fa_new.groupby(['decision','author_category']).size() / df_17_fa_new.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

cat_18_fa = (df_18_fa_new.groupby(['decision','author_category']).size() / df_18_fa_new.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

cat_19_fa = (df_19_fa_new.groupby(['decision','author_category']).size() / df_19_fa_new.groupby(['decision'])
.size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

"""**Contribution of Author Categories**"""

# plot papers decision ratio

hue_order = [ 'Senior','Intermediate','Junior']
fig, ax = plt.subplots(3, 3, figsize=(10.5, 6.6),sharex=True,sharey=True)
sns.barplot( data = df_17_m,x='author_category',y='percentage_count',order=hue_order,ax=ax[0,0])
sns.barplot( data = df_18_m,x='author_category',y='percentage_count',order=hue_order,ax=ax[0,1],)
sns.barplot( data = df_19_m,x='author_category',y='percentage_count',order=hue_order,ax=ax[0,2],)
sns.barplot( data = df_17_s,x='author_category',y='percentage_count',order=hue_order,ax=ax[1,0],)
sns.barplot( data = df_18_s,x='author_category',y='percentage_count',order=hue_order,ax=ax[1,1],)
sns.barplot( data = df_19_s,x='author_category',y='percentage_count',order=hue_order,ax=ax[1,2],)
sns.barplot( data = df_17_fa,x='author_category',y='percentage_count',order=hue_order,ax=ax[2,0],)
sns.barplot( data = df_18_fa,x='author_category',y='percentage_count',order=hue_order,ax=ax[2,1],)
sns.barplot( data = df_19_fa,x='author_category',y='percentage_count',order=hue_order,ax=ax[2,2],)
fig.tight_layout()
ax[0,1].set_ylabel('')
ax[0,2].set_ylabel('')
ax[0,0].set_xlabel('')
ax[0,1].set_xlabel('\n Multiple Authors')
ax[0,2].set_xlabel('')
ax[1,0].set_xlabel('')
ax[1,1].set_xlabel('\n Single Author')
ax[1,2].set_xlabel('')
ax[1,1].set_ylabel('')
ax[1,2].set_ylabel('')
ax[2,0].set_xlabel('')
ax[2,2].set_xlabel('')
ax[2,1].set_ylabel('')
ax[2,2].set_ylabel('')
ax[2,1].set_xlabel('\nFirst Author')
for container in ax[0,0].containers:
    ax[0,0].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[0,1].containers:
    ax[0,1].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[0,2].containers:
    ax[0,2].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[1,0].containers:
    ax[1,0].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[1,1].containers:
    ax[1,1].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[1,2].containers:
    ax[1,2].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[2,0].containers:
    ax[2,0].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[2,1].containers:
    ax[2,1].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[2,2].containers:
    ax[2,2].bar_label(container, fmt='%.0f',weight='bold')
fig.suptitle('Author actegory Statistics',y=1.06)
ax[0,0].set_title('SB-2017')
ax[0,1].set_title('DB-2018')
ax[0,2].set_title('DB-2019')
plt.savefig("auth_cat.pdf",bbox_inches='tight')
fig.show()

"""**Author Category vs Paper Decision**"""

# plot papers decision ratio

hue_order = [ 'Senior','Intermediate','Junior']
fig, ax = plt.subplots(3, 3, figsize=(10.5, 8),sharex=True,sharey=True)
sns.barplot(x ='decision', data = cat_sb_m,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[0,0]).legend_.remove()
sns.barplot(x ='decision', data = cat_18_m,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[0,1],).legend_.remove()
sns.barplot(x ='decision', data = cat_19_m,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[0,2],).legend_.remove()
sns.barplot(x ='decision', data = cat_sb_s,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[1,0],).legend_.remove()
sns.barplot(x ='decision', data = cat_18_s,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[1,1],).legend_.remove()
sns.barplot(x ='decision', data = cat_19_s,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[1,2],).legend_.remove()
sns.barplot(x ='decision', data = cat_sb_fa,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[2,0],).legend_.remove()
sns.barplot(x ='decision', data = cat_18_fa,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[2,1],).legend_.remove()
sns.barplot(x ='decision', data = cat_19_fa,hue='author_category',y='percentage_count',hue_order=hue_order,ax=ax[2,2],).legend_.remove()
fig.tight_layout()
ax[0,1].set_ylabel('')
ax[0,2].set_ylabel('')
ax[0,0].set_xlabel('')
ax[0,1].set_xlabel('\n Multiple Authors')
ax[0,2].set_xlabel('')
ax[1,0].set_xlabel('')
ax[1,1].set_xlabel('\n Single Author')
ax[1,2].set_xlabel('')
ax[1,1].set_ylabel('')
ax[1,2].set_ylabel('')
ax[2,0].set_xlabel('')
ax[2,2].set_xlabel('')
ax[2,1].set_ylabel('')
ax[2,2].set_ylabel('')

for container in ax[0,0].containers:
    ax[0,0].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[0,1].containers:
    ax[0,1].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[0,2].containers:
    ax[0,2].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[1,0].containers:
    ax[1,0].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[1,1].containers:
    ax[1,1].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[1,2].containers:
    ax[1,2].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[2,0].containers:
    ax[2,0].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[2,1].containers:
    ax[2,1].bar_label(container, fmt='%.0f',weight='bold')
for container in ax[2,2].containers:
    ax[2,2].bar_label(container, fmt='%.0f',weight='bold')
fig.suptitle('Decision Percentage',y=1.05)
ax[0,0].set_title('SB-2017')
ax[0,1].set_title('DB-2018')
ax[0,2].set_title('DB-2019')
ax[2,1].set_xlabel('First Author')
ax[2,1].legend(loc="upper center", bbox_to_anchor=(0.5, -.25), ncol=3)

fig.show()
plt.savefig("auth_cat_decision.png",bbox_inches='tight')

# data preperation for combination of junior first author combination

# 2017
comb_auth_17 = new_17_auth_m.groupby(['title','decision'])[['Authors','academic_age','author_category']].agg(list).reset_index()
df_17_fa_comb = comb_auth_17.copy()
df_17_fa_comb['fa_name'] = df_17_fa_comb['Authors'].apply(lambda x:get_first_auth_info(x))
df_17_fa_comb['fa_aa'] = df_17_fa_comb['academic_age'].apply(lambda x:get_first_auth_info(x))

df_17_fa_1 = df_17_fa_comb[['title','decision','Authors','academic_age']]
df_17_fa_e = df_17_fa_1.explode(['Authors','academic_age']).reset_index(drop=True)
df_17_fa_e['auth_category'] = df_17_fa_e.apply(lambda x: get_age_labels(x['academic_age']),axis=1)
df_17_fa_2 = df_17_fa_e.groupby(['title','decision'])[['Authors','academic_age','auth_category']].agg(list).reset_index()
df_17_fa_2.head()

# 2018
comb_auth_18 = new_18_auth_m.groupby(['title','decision'])[['Authors','academic_age','author_category']].agg(list).reset_index()
df_18_fa_comb = comb_auth_18.copy()
df_18_fa_comb['fa_name'] = df_18_fa_comb['Authors'].apply(lambda x:get_first_auth_info(x))
df_18_fa_comb['fa_aa'] = df_18_fa_comb['academic_age'].apply(lambda x:get_first_auth_info(x))

df_18_fa_1 = df_18_fa_comb[['title','decision','Authors','academic_age']]
df_18_fa_e = df_18_fa_1.explode(['Authors','academic_age']).reset_index(drop=True)
df_18_fa_e['auth_category'] = df_18_fa_e.apply(lambda x: get_age_labels(x['academic_age']),axis=1)
df_18_fa_2 = df_18_fa_e.groupby(['title','decision'])[['Authors','academic_age','auth_category']].agg(list).reset_index()
df_18_fa_2.head()

# 2019
comb_auth_19 = new_19_auth_m.groupby(['title','decision'])[['Authors','academic_age','author_category']].agg(list).reset_index()
df_19_fa_comb = comb_auth_19.copy()
df_19_fa_comb['fa_name'] = df_19_fa_comb['Authors'].apply(lambda x:get_first_auth_info(x))
df_19_fa_comb['fa_aa'] = df_19_fa_comb['academic_age'].apply(lambda x:get_first_auth_info(x))

df_19_fa_1 = df_19_fa_comb[['title','decision','Authors','academic_age']]
df_19_fa_e = df_19_fa_1.explode(['Authors','academic_age']).reset_index(drop=True)
df_19_fa_e['auth_category'] = df_19_fa_e.apply(lambda x: get_age_labels(x['academic_age']),axis=1)
df_19_fa_2 = df_19_fa_e.groupby(['title','decision'])[['Authors','academic_age','auth_category']].agg(list).reset_index()
df_19_fa_2.head()

# get the combinations of junior and rest of the categories

def get_comb(cat_list):
  if cat_list[0] == 'Junior':
    if len(cat_list) == 1 : return 'only junior' # only a single junior author
    elif len(cat_list) > 1:
      if len(set(cat_list)) <= 1 == True : return 'junior and junior' # juniors combining with juniors
      if 'Senior' in cat_list and 'Intermediate' not in cat_list : return 'junior and senior' # at least one senior with juniors, no intermed
      if 'Intermediate' in cat_list and 'Senior' not in cat_list : return 'junior and intermediate' # at least one intermed with juniors, no senior
      if all(x in cat_list for x in ['Senior', 'Intermediate']) == True : return 'junior,intermediate,senior' # juniors with at least one senior and intermed
  # elif cat_list[0] == 'Senior' and  'Intermediate' in cat_list and 'Junior' not in cat_list: return 'senior and Intermediate' # Seniors and interm
  # elif cat_list[0] == 'Intermediate' and  'Senior' in cat_list and 'Junior' not in cat_list: return 'Intermediate and senior' # Interm and seniors
  else: return 'NA'

df_17 = df_17_fa_2[['title','decision','auth_category']]
df_17['Combination'] = df_17.auth_category.apply(lambda x : get_comb(x))
df_17 = df_17[df_17.Combination !='NA'].reset_index(drop=True)

df_18 = df_18_fa_2[['title','decision','auth_category']]
df_18['Combination'] = df_18.auth_category.apply(lambda x : get_comb(x))
df_18 = df_18[df_18.Combination !='NA'].reset_index(drop=True)

df_19 = df_19_fa_2[['title','decision','auth_category']]
df_19['Combination'] = df_19.auth_category.apply(lambda x : get_comb(x))
df_19 = df_19[df_19.Combination !='NA'].reset_index(drop=True)


junior_fa_list = ['junior,intermediate,senior','junior and senior','junior and intermediate', 'junior and junior']

df_17_jun =  df_17[df_17.Combination.isin(junior_fa_list)].reset_index(drop=True)
df_18_jun =  df_18[df_18.Combination.isin(junior_fa_list)].reset_index(drop=True)
df_19_jun =  df_19[df_19.Combination.isin(junior_fa_list)].reset_index(drop=True)

comb_17_jun = (df_17_jun.Combination.value_counts()/len(df_17_jun)*100).reset_index().rename(
    {'Combination':'percentage_count','index':'Combination'}, axis=1 )
comb_18_jun = (df_18_jun.Combination.value_counts()/len(df_18_jun)*100).reset_index().rename(
    {'Combination':'percentage_count','index':'Combination'}, axis=1 )
comb_19_jun = (df_19_jun.Combination.value_counts()/len(df_19_jun)*100).reset_index().rename(
    {'Combination':'percentage_count','index':'Combination'}, axis=1 )

hue_17_jun = (df_17_jun.groupby(['Combination','decision']).size() /
             df_17_jun.groupby(['decision']).size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

hue_18_jun = (df_18_jun.groupby(['Combination','decision']).size() /
             df_18_jun.groupby(['decision']).size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

hue_19_jun = (df_19_jun.groupby(['Combination','decision']).size() /
             df_19_jun.groupby(['decision']).size()*100).reset_index().rename({0:'percentage_count'}, axis=1)

"""**Contribution of Author Categories - Author Combination**"""

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(15, 5.5))
order = ['junior,intermediate,senior','junior and senior','junior and intermediate','junior and junior']
sns.barplot(y = 'Combination',data = comb_17_jun,x='percentage_count',ax=ax1,
           palette='rocket',order=order)#palette='rocket'
sns.barplot(y = 'Combination',data = comb_18_jun,x='percentage_count',ax=ax2,order=order,
            palette='rocket').set(yticklabels=[])
sns.barplot(y = 'Combination',data = comb_19_jun,x='percentage_count',ax=ax3,palette='rocket',order=order).set(yticklabels=[])
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.1f',weight='bold',fontsize=12)
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.1f',weight='bold',fontsize=12)
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.1f',weight='bold',fontsize=12)
ax1.set_xlim([0, 50])
ax2.set_xlim([0, 50])
ax3.set_xlim([0, 50])
ax1.set_yticklabels(ax1.get_yticklabels(), fontsize=12)
ax2.set_ylabel('')
ax3.set_ylabel('')
ax1.set_xlabel('')
ax3.set_xlabel('')
ax2.set_xlabel('Percentage count',fontdict={ 'fontsize': 13})
ax1.set_ylabel('Collaboration',fontdict={ 'fontsize': 13})
fig.suptitle('First Author Combinations',y=1,)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
# ax1.tick_params(axis='x', rotation=80)
# ax2.tick_params(axis='x', rotation=80)
# ax3.tick_params(axis='x', rotation=80)
fig.tight_layout()
plt.savefig("fa_junior_comb.png", bbox_inches="tight")
fig.show()

"""**Author Category vs Paper Decision - Author Combination**"""

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(13, 5.5))
order = ['junior,intermediate,senior','junior and senior','junior and intermediate','junior and junior']
sns.barplot(hue = 'Combination',data = hue_17_jun,x='percentage_count',ax=ax1,y='decision',
            hue_order=order,palette='rocket').legend_.remove()#palette='rocket'
g = sns.barplot(hue = 'Combination',data = hue_18_jun,x='percentage_count',ax=ax2,y='decision',
            hue_order=order,palette='rocket').set(yticklabels=[])

ax = sns.barplot(hue = 'Combination',data = hue_19_jun,x='percentage_count',ax=ax3,hue_order=order,
            y='decision',palette='rocket')
ax.set(yticklabels=[])
ax.legend_.remove()
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.1f',weight='bold',fontsize=11)
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.1f',weight='bold',fontsize=11)
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.1f',weight='bold',fontsize=11)

ax1.set_yticklabels(ax1.get_yticklabels(), fontsize=12)
ax2.set_ylabel('')
ax3.set_ylabel('')
ax2.get_yticklabels('')
ax3.get_yticklabels('')

ax1.set_xlabel('')
ax3.set_xlabel('')

ax1.set_ylabel('Decision',fontdict={ 'fontsize': 12})
fig.suptitle('First author Collaboration and descision',y=1,)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
ax1.set_xlim([0, 100])
ax2.set_xlim([0, 100])
ax3.set_xlim([0, 100])
# ax1.tick_params(axis='x', rotation=80)
# ax2.tick_params(axis='x', rotation=80)
# ax3.tick_params(axis='x', rotation=80)

ax2.legend(loc="upper center", bbox_to_anchor=(0.5, -.08), ncol=4,fontsize=11)
ax2.set_xlabel('\n\n\nPercentage count',fontdict={ 'fontsize': 12})

# fig.tight_layout()
plt.savefig("fa_junior_hue.png", bbox_inches="tight")
plt.show()

df_17_rev_one['avg_rating'] = df_17_rev_one['rating_score'].apply(lambda x: np.average(x, weights=x))
df_17_rev_one['confidence_score'] = df_17_rev_one['confidence_score'].apply(lambda x: [int(i) for i in x])
df_17_rev_one['avg_cs'] = df_17_rev_one['confidence_score'].apply(lambda x: np.average(x, weights=x))

df_18_rev_one['avg_cs'] = df_18_rev_one['confidence_score'].apply(lambda x: np.average(x, weights=x))
df_18_rev_one['avg_rating'] = df_18_rev_one['rating_score'].apply(lambda x: np.average(x, weights=x))

df_19_rev_one['avg_cs'] = df_19_rev_one['confidence_score'].apply(lambda x: np.average(x, weights=x))
df_19_rev_one['avg_rating'] = df_19_rev_one['rating_score'].apply(lambda x: np.average(x, weights=x))

df_17_auth_one_e = df_17_auth_one.explode(['Authors','academic_age','current_age','total_num_pub']).reset_index(drop=True)
df_18_auth_one_e = df_18_auth_one.explode(['Authors','academic_age','current_age','total_num_pub']).reset_index(drop=True)
df_19_auth_one_e = df_19_auth_one.explode(['Authors','academic_age','current_age','total_num_pub']).reset_index(drop=True)

df_auth_rev_17_one = new_17_auth_s.merge(df_17_rev_one[['title', 'avg_cs','avg_rating']],on='title')
df_auth_rev_18_one = new_18_auth_s.merge(df_18_rev_one[['title', 'avg_cs','avg_rating']],on='title')
df_auth_rev_19_one = new_19_auth_s.merge(df_19_rev_one[['title', 'avg_cs','avg_rating']],on='title')

"""**Author Category VS Ratings**"""

# single author

hue_order=['Senior','Intermediate','Junior']

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(13, 4))
sns.barplot(x ='author_category', y ='avg_rating', data = df_auth_rev_17_one,errorbar=('ci', 0),ax=ax1,order=hue_order)
sns.barplot(x ='author_category', y ='avg_rating', data = df_auth_rev_18_one,errorbar=('ci', 0),ax=ax2,order=hue_order)
sns.barplot(x ='author_category', y ='avg_rating', data = df_auth_rev_19_one,errorbar=('ci', 0),ax=ax3,order=hue_order)
# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold')
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold')
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold')
ax1.set_ylim([0, 7.3])
ax2.set_ylim([0, 7.3])
ax3.set_ylim([0, 7.3])
ax2.set_ylabel('')
ax3.set_ylabel('')
ax3.set_xlabel('')
ax1.set_xlabel('')
ax2.set_xlabel('\nSingle author category',fontdict={ 'fontsize': 12})
ax1.set_ylabel('Average rating',fontdict={ 'fontsize': 12})
fig.suptitle('Rating VS author category-Single Author',y=1.1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
plt.savefig('Rating_singleauthor_cat.png',bbox_inches="tight")
plt.show()

# first author

df_17_rev_m_fa = df_17_rev_m[['title','decision','rating_score','confidence_score']]
df_17_rev_m_fa = df_17_rev_m_fa.explode(['rating_score','confidence_score'])
df_17_auth_rev_m_fa = df_17_fa_new.merge(df_17_rev_m_fa[['title','rating_score','confidence_score']],on='title')

df_18_rev_m_fa = df_18_rev_m[['title','decision','rating_score','confidence_score']]
df_18_rev_m_fa = df_18_rev_m_fa.explode(['rating_score','confidence_score'])
df_18_auth_rev_m_fa = df_18_fa_new.merge(df_18_rev_m_fa[['title','rating_score','confidence_score']],on='title')

df_19_rev_m_fa = df_19_rev_m[['title','decision','rating_score','confidence_score']]
df_19_rev_m_fa = df_19_rev_m_fa.explode(['rating_score','confidence_score'])
df_19_auth_rev_m_fa = df_19_fa_new.merge(df_19_rev_m_fa[['title','rating_score','confidence_score']],on='title')

hue_order=['Senior','Intermediate','Junior']

fig, ax = plt.subplots(1, 3, figsize=(14, 5))
sns.barplot(x ='author_category', y ='rating_score', data = df_17_auth_rev_m_fa,errorbar=('ci', 0),ax=ax[0],order=hue_order)
sns.barplot(x ='author_category', y ='rating_score', data = df_18_auth_rev_m_fa,errorbar=('ci', 0),ax=ax[1],order=hue_order)
sns.barplot(x ='author_category', y ='rating_score', data = df_19_auth_rev_m_fa,errorbar=('ci', 0),ax=ax[2],order=hue_order)
# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
for container in ax[0].containers:
    ax[0].bar_label(container, fmt='%.2f')
for container in ax[1].containers:
    ax[1].bar_label(container, fmt='%.2f')
for container in ax[2].containers:
    ax[2].bar_label(container, fmt='%.2f')

ax[0].set_ylim([0, 7.3])
ax[1].set_ylim([0, 7.3])
ax[2].set_ylim([0, 7.3])

# ax[0,0].set_ylabel('')
ax[1].set_ylabel('')
ax[2].set_ylabel('')
ax[0].set_xlabel('')
ax[1].set_xlabel('\nFisrt author category')
ax[2].set_xlabel('')

# ax2.set_xlabel('\nauthor category')
fig.suptitle('RS VS First Author Category',y=1)
ax[0].set_title('SB-2017')
ax[1].set_title('DB-2018')
ax[2].set_title('DB-2019')

plt.savefig("RS vs first Category.png")
plt.show()

# comb of authors

df_17_fa_comb_new = df_17.merge(df_17_rev_m_fa[['title','rating_score','confidence_score']],on='title')
df_18_fa_comb_new = df_18.merge(df_18_rev_m_fa[['title','rating_score','confidence_score']],on='title')
df_19_fa_comb_new = df_19.merge(df_19_rev_m_fa[['title','rating_score','confidence_score']],on='title')

# order_auth = ['Senior','Intermediate', 'Junior']
junior_fa_list = ['junior,intermediate,senior','junior and senior','junior and intermediate', 'junior and junior']
# hue_1 = ['Confident', 'Medium Confident', 'Less confident']

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(15, 5.5))
sns.barplot(df_17_fa_comb_new,x='rating_score',errorbar=None,y='Combination',
            ax=ax1,order = junior_fa_list,palette='rocket')
# g.legend_.remove()
sns.barplot(df_18_fa_comb_new,x='rating_score',errorbar=None,y='Combination',
            ax=ax2,order = junior_fa_list,palette='rocket').set(yticklabels=[])
sns.barplot(df_19_fa_comb_new,x='rating_score',errorbar=None,y='Combination',
            ax=ax3,order = junior_fa_list,palette='rocket').set(yticklabels=[])
# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
fig.suptitle('Rating VS Category',y=1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
ax2.set_ylabel('')
ax3.set_ylabel('')
ax1.set_xlabel('')
ax3.set_xlabel('')
# ax1.set_xlim([0, 6])
ax2.set_xlim([0, 6])
ax3.set_xlim([0, 6])
ax1.set_yticklabels(ax1.get_yticklabels(), fontsize=12)
ax2.set_xlabel('Ratings',fontdict={ 'fontsize': 13})
ax1.set_ylabel('Collaboration',fontdict={ 'fontsize': 13})
plt.savefig('Rating_junior_collaboration.png',bbox_inches="tight")
plt.show()

"""**Author Category VS Confidence Score**"""

# single author

fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(14, 4))
sns.barplot(hue ='author_category', y ='avg_cs', data = df_auth_rev_17_one,x='decision',errorbar=('ci', 0),ax=ax1,
            hue_order=hue_order,order=['Accept','Reject']).legend_.remove()
sns.barplot(hue ='author_category', y ='avg_cs', data = df_auth_rev_18_one,x='decision',errorbar=('ci', 0),ax=ax2,hue_order=hue_order,
            order=['Accept','Reject'])
sns.barplot(hue ='author_category', y ='avg_cs', data = df_auth_rev_19_one,x='decision',errorbar=('ci', 0),ax=ax3,
            hue_order=hue_order,order=['Accept','Reject']).legend_.remove()

for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold')
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold')
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold')
ax1.set_ylim([0, 5])
ax2.set_ylim([0, 5])
ax3.set_ylim([0, 5])
ax2.set_ylabel('')
ax1.set_xlabel('')
ax3.set_xlabel('')
ax1.set_xlabel('')
ax1.set_ylabel('Average CS',fontdict={ 'fontsize': 12})

fig.suptitle('CS VS Author Category- One author',y=1.1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
ax2.legend(loc="upper center", bbox_to_anchor=(0.5, -.08), ncol=3)
ax2.set_xlabel('\n\nPaper Decision',fontdict={ 'fontsize': 12})
plt.savefig('CS_singleauthor_cat.png',bbox_inches='tight')
plt.show()

# comb authors

# order_auth = ['Senior','Intermediate', 'Junior']
junior_fa_list = ['junior,intermediate,senior','junior and senior','junior and intermediate', 'junior and junior']
hue_1 = ['Accept', 'Reject']
palette = [ "#ffcc00","#993300",]
fig, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(15,5))
sns.barplot(df_17_fa_comb_new,x='confidence_score',errorbar=None,y='Combination',
            ax=ax1,order = junior_fa_list,hue='decision',palette=palette,hue_order=hue_1).legend_.remove()
g = sns.barplot(df_18_fa_comb_new,x='confidence_score',errorbar=None,y='Combination',
            ax=ax2,order = junior_fa_list,hue='decision',palette=palette,hue_order=hue_1)
g.set(yticklabels=[])

ax = sns.barplot(df_19_fa_comb_new,x='confidence_score',errorbar=None,y='Combination',
            ax=ax3,order = junior_fa_list,hue='decision',palette=palette,hue_order=hue_1)
ax.set(yticklabels=[])
ax.legend_.remove()
# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
for container in ax1.containers:
    ax1.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
for container in ax2.containers:
    ax2.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
for container in ax3.containers:
    ax3.bar_label(container, fmt='%.2f',weight='bold',fontsize=12)
fig.suptitle('CS VS Author Combination',y=1)
ax1.set_title('SB-2017')
ax2.set_title('DB-2018')
ax3.set_title('DB-2019')
ax2.set_ylabel('')
ax3.set_ylabel('')
ax1.set_xlabel('')
ax3.set_xlabel('')
ax1.set_xlim([0, 5])
ax2.set_xlim([0, 5])
ax3.set_xlim([0, 5])
ax1.set_yticklabels(ax1.get_yticklabels(), fontsize=12)
ax1.set_ylabel('Collaboration',fontdict={ 'fontsize': 13})
ax2.legend(loc="upper center", bbox_to_anchor=(0.5, -.08), ncol=2, fontsize=12)
ax2.set_xlabel('\n\n\nConfidence scores',fontdict={ 'fontsize': 13})
plt.savefig('CS_junior_collaboration.png',bbox_inches="tight")
plt.show()

"""# **Statistical Analysis**"""

!pip install statsmodels

import statsmodels.api as sm

"""**Rating vs Academic Age**"""

# review
df_17_rev_m_new = df_17_rev_m[['title','decision','rating_score','confidence_score']]
df_17_rev_m_new = df_17_rev_m_new.explode(['rating_score','confidence_score'])

# author
new_17_auth_m_new = new_17_auth_m[['title','Authors','academic_age','current_age']]

# merge
df_17_auth_rev_m_stat = new_17_auth_m_new.merge(df_17_rev_m_new[['title','rating_score','confidence_score']],on='title')

# datatype conversion

df_17_auth_rev_m_stat['academic_age'] = df_17_auth_rev_m_stat['academic_age'].astype('int')
df_17_auth_rev_m_stat['current_age'] = df_17_auth_rev_m_stat['current_age'].astype('int')
df_17_auth_rev_m_stat['rating_score'] = df_17_auth_rev_m_stat['rating_score'].astype('int')

# Apply OLS regression
res_sb_rs = sm.OLS(endog=df_17_auth_rev_m_stat['rating_score'], exog=df_17_auth_rev_m_stat[['academic_age']]).fit()
print(res_sb_rs.summary())

# review
df_18_rev_m_new = df_18_rev_m[['title','decision','rating_score','confidence_score']]
df_18_rev_m_new = df_18_rev_m_new.explode(['rating_score','confidence_score'])

# author
new_18_auth_m_new = new_18_auth_m[['title','Authors','academic_age','current_age']]

# merge
df_18_auth_rev_m_stat = new_18_auth_m_new.merge(df_18_rev_m_new[['title','rating_score','confidence_score']],on='title')

# datatype conversion

df_18_auth_rev_m_stat['academic_age'] = df_18_auth_rev_m_stat['academic_age'].astype('int')
df_18_auth_rev_m_stat['current_age'] = df_18_auth_rev_m_stat['current_age'].astype('int')
df_18_auth_rev_m_stat['rating_score'] = df_18_auth_rev_m_stat['rating_score'].astype('int')

# Apply OLS regression
res_sb_rs = sm.OLS(endog=df_18_auth_rev_m_stat['rating_score'], exog=df_18_auth_rev_m_stat[['academic_age']]).fit()
print(res_sb_rs.summary())

# review
df_19_rev_m_new = df_19_rev_m[['title','decision','rating_score','confidence_score']]
df_19_rev_m_new = df_19_rev_m_new.explode(['rating_score','confidence_score'])

# author
new_19_auth_m_new = new_19_auth_m[['title','Authors','academic_age','current_age']]

# merge
df_19_auth_rev_m_stat = new_19_auth_m_new.merge(df_19_rev_m_new[['title','rating_score','confidence_score']],on='title')

# datatype conversion

df_19_auth_rev_m_stat['academic_age'] = df_19_auth_rev_m_stat['academic_age'].astype('int')
df_19_auth_rev_m_stat['current_age'] = df_19_auth_rev_m_stat['current_age'].astype('int')
df_19_auth_rev_m_stat['rating_score'] = df_19_auth_rev_m_stat['rating_score'].astype('int')

# Apply OLS regression
res_sb_rs = sm.OLS(endog=df_19_auth_rev_m_stat['rating_score'], exog=df_19_auth_rev_m_stat[['academic_age']]).fit()
print(res_sb_rs.summary())

"""**CS vs Academic Age**"""

df_17_auth_rev_m_stat['confidence_score'] = df_17_auth_rev_m_stat['confidence_score'].astype('int')

# Apply OLS regression
res_sb_rs = sm.OLS(endog=df_17_auth_rev_m_stat['confidence_score'], exog=df_17_auth_rev_m_stat[['academic_age']]).fit()
print(res_sb_rs.summary())

df_18_auth_rev_m_stat['confidence_score'] = df_18_auth_rev_m_stat['confidence_score'].astype('int')

# Apply OLS regression
res_sb_rs = sm.OLS(endog=df_18_auth_rev_m_stat['confidence_score'], exog=df_18_auth_rev_m_stat[['academic_age']]).fit()
print(res_sb_rs.summary())

df_19_auth_rev_m_stat['confidence_score'] = df_19_auth_rev_m_stat['confidence_score'].astype('int')

# Apply OLS regression
res_sb_rs = sm.OLS(endog=df_19_auth_rev_m_stat['confidence_score'], exog=df_19_auth_rev_m_stat[['academic_age']]).fit()
print(res_sb_rs.summary())